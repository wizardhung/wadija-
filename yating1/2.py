# -*- coding: utf-8 -*-
import os, json, threading, time, audioop, math, array, wave
import requests, websocket, pyaudio
from websocket._exceptions import WebSocketConnectionClosedException
from google.cloud import speech

# ===== Yating è¨­å®š =====
API_KEY  = os.getenv("YATING_API_KEY") or "e0b11545ab32fd588ef18437591ea9ffbc68445f"
PIPELINE = "asr-zh-en-std"
TOKEN_URL = "https://asr.api.yating.tw/v1/token"
WS_URL    = "wss://asr.api.yating.tw/ws/v1/"

TARGET_RATE = 16000
FORMAT = pyaudio.paInt16
CHANNELS = 1
FRAMES_PER_BUFFER = 1000
WAVE_OUTPUT_FILENAME = "recorded.wav"

# æ”¶é›†å·²è½‰æˆ 16 kHz çš„éŸ³è¨Šç‰‡æ®µ
frames = []

def dBFS(data: bytes) -> float:
    if not data: return -120.0
    a = array.array('h', data)
    if not a: return -120.0
    mean_sq = sum(x*x for x in a)/len(a)
    if mean_sq <= 1: return -120.0
    rms = math.sqrt(mean_sq)/32768.0
    return 20*math.log10(rms)

def choose_input_device(pa: pyaudio.PyAudio) -> int | None:
    print("ğŸ” å¯ç”¨è¼¸å…¥è£ç½®ï¼š")
    for i in range(pa.get_device_count()):
        info = pa.get_device_info_by_index(i)
        if int(info.get("maxInputChannels", 0)) > 0:
            print(f"  index={i:2d} | name={info.get('name','')} | defaultRate={int(info.get('defaultSampleRate',0))}Hz")
    s = input("è«‹è¼¸å…¥è¦ä½¿ç”¨çš„ indexï¼ˆç›´æ¥ Enter ç”¨ç³»çµ±é è¨­ï¼‰: ").strip()
    if s == "": return None
    try: return int(s)
    except: return None

def get_token() -> str:
    r = requests.post(
        TOKEN_URL,
        headers={"key": API_KEY, "Content-Type": "application/json"},
        json={"pipeline": PIPELINE},
        timeout=10
    )
    r.raise_for_status()
    token = r.json().get("auth_token")
    if not token:
        raise RuntimeError("No auth_token in response.")
    return token

def open_stream(pa: pyaudio.PyAudio, wanted_index: int | None):
    """å„ªå…ˆ 16k é–‹å•Ÿï¼›å¤±æ•—å‰‡æ‹‹éŒ¯ï¼ˆæˆ‘å€‘å·²åšé‡å–æ¨£ï¼Œæ‰€ä»¥è£ç½®ä¸å¿…æ”¯æ´ 16kï¼‰"""
    try:
        st = pa.open(format=FORMAT, channels=CHANNELS, rate=TARGET_RATE, input=True,
                     frames_per_buffer=FRAMES_PER_BUFFER,
                     input_device_index=wanted_index if wanted_index is not None else None)
        return st, TARGET_RATE
    except Exception:
        # è‹¥ä½ çš„è£ç½®ä¸åƒ 16kï¼Œå¯æ”¹ç‚ºè£ç½®é è¨­ç‡ï¼Œç„¶å¾Œæˆ‘å€‘å†é‡å–æ¨£
        info = pa.get_device_info_by_index(wanted_index) if wanted_index is not None else pa.get_default_input_device_info()
        fallback_rate = int(info.get("defaultSampleRate", 44100)) or 44100
        st = pa.open(format=FORMAT, channels=CHANNELS, rate=fallback_rate, input=True,
                     frames_per_buffer=FRAMES_PER_BUFFER,
                     input_device_index=wanted_index if wanted_index is not None else None)
        return st, fallback_rate

def to_16k(data: bytes, in_rate: int) -> bytes:
    if in_rate == TARGET_RATE:
        return data
    out, _ = audioop.ratecv(data, 2, 1, in_rate, TARGET_RATE, None)
    return out

def flush_final(ws, wait_sec: float = 4.0) -> str:
    """
    åªè² è²¬æŠŠ Yating çš„ final å¥å­æ‹¿å›ä¾†ä¸¦å›å‚³æ–‡å­—ã€‚
    ä¸åœ¨é€™è£¡åš Google STTã€‚
    """
    deadline = time.time() + wait_sec
    got_any = False
    while time.time() < deadline:
        try:
            frame = ws.recv_frame()
            if frame and frame.opcode == websocket.ABNF.OPCODE_TEXT:
                payload = json.loads(frame.data.decode("utf-8"))
                got_any = True
                pipe = payload.get("pipe", {})
                if payload.get("error") or pipe.get("error"):
                    print("[server][error]", payload)
                if pipe.get("asr_final"):
                    text = pipe.get("asr_sentence") or ""
                    return text
        except websocket.WebSocketTimeoutException:
            pass
        except WebSocketConnectionClosedException:
            print("[debug] é€£ç·šå·²é—œé–‰ï¼ˆå¯èƒ½åŒæ™‚è®€å¯«æˆ–ç¶²è·¯ä¸­æ–·ï¼‰")
            return ""
    if not got_any:
        print("[debug] æ²’æ”¶åˆ°ä¼ºæœå™¨å›å‚³ï¼ˆå¯èƒ½ç¶²è·¯/é˜²ç«ç‰†/ç­‰å€™å¤ªçŸ­ï¼‰")
    return ""

def save_wave(frames_list, rate=TARGET_RATE):
    """frames_list å…§æ˜¯ 16k çš„åŸå§‹ PCMï¼›é€™è£¡ä¸€å¾‹ç”¨ TARGET_RATE å­˜æª”"""
    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
    pa = pyaudio.PyAudio()
    try:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(pa.get_sample_size(FORMAT))
        wf.setframerate(TARGET_RATE)
        wf.writeframes(b''.join(frames_list))
    finally:
        wf.close()
        pa.terminate()

def run_google_stt(filename) -> str:
    """
    è®€å– WAVï¼Œå–å‰ 55 ç§’çš„åŸå§‹ PCM é€åˆ° Google STTã€‚
    å›å‚³ä¸­æ–‡/å°èª/è‹±æ–‡/ç„¡æ³•åˆ¤æ–·ã€‚
    """
    MAX_SEC = 55

    # è®€ WAV å–å¾—åŸå§‹ PCMï¼ˆå»æ‰ WAV headerï¼‰
    import wave
    with wave.open(filename, "rb") as wf:
        channels = wf.getnchannels()
        sampwidth = wf.getsampwidth()
        rate = wf.getframerate()
        nframes = wf.getnframes()

        # å–æœ€å¤š MAX_SEC ç§’
        max_frames = min(nframes, int(MAX_SEC * rate))
        pcm_bytes = wf.readframes(max_frames)

    # æº–å‚™ Google STT
    client = speech.SpeechClient()
    audio = speech.RecognitionAudio(content=pcm_bytes)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,  # æˆ‘å€‘å­˜çš„æ˜¯ 16-bit PCM
        sample_rate_hertz=rate,                                     # ç”¨æª”æ¡ˆå¯¦éš›å–æ¨£ç‡
        language_code="zh-TW",
        alternative_language_codes=["en-US", "nan-TW"],
        enable_automatic_punctuation=True,
    )

    try:
        response = client.recognize(config=config, audio=audio)
    except Exception as e:
        print(f"ğŸŒ Googleèªè¨€åµæ¸¬ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return "ç„¡æ³•åˆ¤æ–·"

    if not response.results:
        return "ç„¡æ³•åˆ¤æ–·"

    transcript = response.results[0].alternatives[0].transcript.strip()

    # ç²—ç•¥èªè¨€åˆ¤æ–·ï¼ˆå¯æŒ‰éœ€åŠ å¼·ï¼‰
    if any(w in transcript.lower() for w in ["the", "is", "my", "name", "you", "hello"]):
        return "è‹±æ–‡"
    if any(t in transcript for t in ["æ¬²", "å’±", "æ", "æ±", "å˜›æœƒ", "æ•¢æœƒ", "é£Ÿé£¯", "è¬›", "ç„¡å•¥ç‰©"]):
        return "å°èª"
    if any('\u4e00' <= ch <= '\u9fff' for ch in transcript):
        return "ä¸­æ–‡"
    return "ç„¡æ³•åˆ¤æ–·"


def main():
    token = get_token()
    ws = websocket.create_connection(f"{WS_URL}?token={token}")
    ws.settimeout(2.0)

    pa = pyaudio.PyAudio()
    idx = choose_input_device(pa)
    stream, in_rate = open_stream(pa, idx)

    recording = threading.Event()
    quitting  = threading.Event()
    ws_lock = threading.Lock()

    def input_worker():
        print("ï¼ˆæŒ‰ Enter é–‹å§‹/åœæ­¢éŒ„éŸ³ï¼›è¼¸å…¥ q + Enter çµæŸï¼‰")
        while not quitting.is_set():
            s = input()
            if s.strip().lower() == "q":
                quitting.set()
                if recording.is_set():
                    with ws_lock:
                        ws.send(b"", opcode=websocket.ABNF.OPCODE_BINARY)  # EOS 1
                        time.sleep(0.1)
                        ws.send(b"", opcode=websocket.ABNF.OPCODE_BINARY)  # EOS 2
                break

            if recording.is_set():
                # åœæ­¢
                recording.clear()
                print("ğŸ”´ çµæŸéŒ„éŸ³ï¼Œè™•ç†ä¸­...")

                # é€ EOSï¼Œå…ˆæŠŠ frames å­˜æª”ï¼Œå†å– finalï¼Œå†è·‘ Google
                with ws_lock:
                    ws.send(b"", opcode=websocket.ABNF.OPCODE_BINARY)
                    time.sleep(0.1)
                    ws.send(b"", opcode=websocket.ABNF.OPCODE_BINARY)

                # é‡è¦ï¼å…ˆå­˜æª”ï¼ˆframes æ˜¯ 16kï¼‰
                save_wave(frames, TARGET_RATE)

                # å†æ‹¿ Yating çš„ final
                text = flush_final(ws, wait_sec=4.0) or ""

                # ç”¨ Google åˆ¤èªè¨€
                lang = run_google_stt(WAVE_OUTPUT_FILENAME)

                # ä¾ä½ è¦çš„æ ¼å¼è¼¸å‡º
                print(f"ğŸ“ è¾¨è­˜çµæœ: {text}")
                print(f"ğŸ“Š ä¿¡å¿ƒåº¦: N/A")
                print(f"ğŸŒ åµæ¸¬èªè¨€ï¼š{lang}")

            else:
                # é–‹å§‹
                frames.clear()
                recording.set()
                print("ğŸŸ¢ é–‹å§‹éŒ„éŸ³")

    threading.Thread(target=input_worker, daemon=True).start()

    last_vu = 0.0
    try:
        while not quitting.is_set():
            data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)

            # é¡¯ç¤ºéŸ³é‡
            if time.time() - last_vu > 0.5:
                print(f"[mic] {dBFS(data):.1f} dBFS")
                last_vu = time.time()

            # éŒ„éŸ³ä¸­å°±é‡å–æ¨£â†’æ¨çµ¦ Yatingï¼ŒåŒæ™‚å¯«å…¥ frames
            if recording.is_set():
                payload = to_16k(data, in_rate)
                frames.append(payload)
                with ws_lock:
                    try:
                        ws.send(payload, opcode=websocket.ABNF.OPCODE_BINARY)
                    except WebSocketConnectionClosedException:
                        print("[debug] é€£ç·šå·²é—œé–‰ï¼ˆå‚³é€æ™‚ï¼‰")
                        quitting.set()
                        break

    finally:
        try:
            with ws_lock:
                ws.send(b"", opcode=websocket.ABNF.OPCODE_BINARY)
        except Exception:
            pass
        try: ws.close()
        except Exception:
            pass
        try: stream.stop_stream(); stream.close(); pa.terminate()
        except Exception:
            pass

if __name__ == "__main__":
    main()
